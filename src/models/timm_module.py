"""
timmãƒ™ãƒ¼ã‚¹ã®LightningModuleï¼ˆè»¢ç§»å­¦ç¿’å¯¾å¿œï¼‰
Classification Report & Confusion Matrixå¯¾å¿œ
"""
import pandas as pd
import torch
import torch.nn as nn
import pytorch_lightning as pl
import timm
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import wandb


class TimmLitModule(pl.LightningModule):
    """
    timmãƒ™ãƒ¼ã‚¹ã®LightningModule
    - è»¢ç§»å­¦ç¿’ï¼ˆtransfer learningï¼‰å¯¾å¿œ
    - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆfine-tuningï¼‰å¯¾å¿œ
    - Classification Report & Confusion Matrixå¯¾å¿œ
    """
    
    def __init__(
        self, 
        model_name="efficientnet_b0",
        num_classes=10, 
        lr=1e-3,
        pretrained=True,
        freeze_backbone=False,
        class_names=None, #ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    ):
        super().__init__()
        self.save_hyperparameters()
        
        # timmã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        self.model = timm.create_model(
            model_name,
            pretrained=pretrained,
            num_classes=num_classes,
        )
        
        # è»¢ç§»å­¦ç¿’: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’å‡çµ
        if freeze_backbone:
            self._freeze_backbone()
        
        self.criterion = nn.CrossEntropyLoss()
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®äºˆæ¸¬ã¨ãƒ»ãƒ©ãƒ™ãƒ«ä¿å­˜
        self.test_preds = []
        self.test_labels = []
    
    def _freeze_backbone(self):
        """ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆç‰¹å¾´æŠ½å‡ºéƒ¨åˆ†ï¼‰ã‚’å‡çµ"""
        print("ğŸ”’ ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’å‡çµï¼ˆè»¢ç§»å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼‰")
        
        for name, param in self.model.named_parameters():
            if not any(x in name for x in ['classifier', 'head', 'fc']):
                param.requires_grad = False
        
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {trainable_params:,} / {total_params:,} "
              f"({100 * trainable_params / total_params:.1f}%)")
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)
        preds = logits.argmax(dim=1)
        acc = (preds == y).float().mean()
        
        self.log("train/loss", loss, prog_bar=True)
        self.log("train/acc", acc, prog_bar=True)
        self.log("train/lr", self.optimizers().param_groups[0]['lr'])
        
        return loss
    
    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)
        preds = logits.argmax(dim=1)
        acc = (preds == y).float().mean()
        
        self.log("val/loss", loss, prog_bar=True)
        self.log("val/acc", acc, prog_bar=True)
        
        return loss
    
    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)
        preds = logits.argmax(dim=1)
        acc = (preds == y).float().mean()
        
        # äºˆæ¸¬ã¨ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜
        self.test_preds.append(preds)
        self.test_labels.append(y)
        
        self.log("test/loss", loss, prog_bar=True)
        self.log("test/acc", acc, prog_bar=True)
        
        return loss
    
    # ========== ãƒ†ã‚¹ãƒˆçµ‚äº†æ™‚ã«å‘¼ã°ã‚Œã‚‹ ==========
    def on_test_epoch_end(self):
        """ 
        ãƒ†ã‚¹ãƒˆçµ‚ã‚ã£ãŸå¾Œã«å‘¼ã°ã‚Œã‚‹
        Classification Report ã¨ Confusion Matrixã‚’ä½œæˆ
        """
        # å…¨ãƒãƒƒãƒã®äºˆæ¸¬ã¨ãƒ©ãƒ™ãƒ«ã‚’çµåˆ
        all_preds = torch.cat(self.test_preds).cpu().numpy()
        all_labels = torch.cat(self.test_labels).cpu().numpy()
        
        # ã‚¯ãƒ©ã‚¹åã‚’å–å¾—
        class_names = self.hparams.class_names
        if class_names is None:
            class_names = [f"Class_{i}" for i in range(self.hparams.num_classes)]
        
        # ========== Classification Report ==========
        print("\n" + "="*60)
        print("Classification Report")
        print("="*60)
        
        report_report = classification_report(
            all_labels, 
            all_preds, 
            target_names=class_names,
            digits=4
        )
        print(report_report)
        
        # è¾æ›¸å½¢å¼(W&Bç”¨)
        report_dict = classification_report(
            all_labels,
            all_preds,
            target_names=class_names,
            output_dict=True
        )
        
        # ========== W&Bã«ä¿å­˜ï¼ˆæ­£ã—ã„æ–¹æ³•ï¼‰ ==========
        if self.logger:
            #1. Tableã¨ã—ã¦ä¿å­˜
            report_df = pd.DataFrame(report_dict).transpose()
            self.logger.experiment.log({
                "classification_report_table": wandb.Table(dataframe=report_df)
            })
            
            #2. å„ã‚¯ãƒ©ã‚¹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å€‹åˆ¥ã«ä¿å­˜
            for class_name, metrics in report_dict.items():
                if isinstance(metrics, dict) and 'precision' in metrics:
                    self.logger.experiment.log({
                        f"test_metrics/{class_name}/precision": metrics['precision'],
                        f"test_metrics/{class_name}/recall": metrics['recall'],
                        f"test_metrics/{class_name}/f1-score": metrics['f1-score'],
                        f"test_metrics/{class_name}/support": metrics['support'],
                    })
                    
            # 3. å…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            self.logger.experiment.log({
                "test/accuracy": report_dict['accuracy'],
                "test/macro_avg/precision": report_dict['macro avg']['precision'],
                "test/macro_avg/recall": report_dict['macro avg']['recall'],
                "test/macro_avg/f1-score": report_dict['macro avg']['f1-score'],
                "test/weighted_avg/precision": report_dict['weighted avg']['precision'],
                "test/weighted_avg/recall": report_dict['weighted avg']['recall'],
                "test/weighted_avg/f1-score": report_dict['weighted avg']['f1-score'],
            })
            
            print("âœ… Classification Report ã‚’ W&B ã«ä¿å­˜å®Œäº†")
                    
    
        # ========== Confusion Matrix ==========
        cm = confusion_matrix(all_labels, all_preds)
        
        fig, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=class_names, yticklabels=class_names, ax=ax)
        ax.set_xlabel('Predicted')
        ax.set_ylabel('True')
        ax.set_title('Confusion Matrix')
        plt.tight_layout()
        
        if self.logger:
            # W&Bå°‚ç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç‰ˆ
            self.logger.experiment.log({
                "confusion_matrix": wandb.plot.confusion_matrix(
                    probs=None,
                    y_true=all_labels,
                    preds=all_preds,
                    class_names=class_names
                ),
                # Seabornã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
                "confusion_matrix_heatmap": wandb.Image(fig)
            })
        
        fig.savefig("confusion_matrix.png", dpi=150, bbox_inches='tight')
        plt.close(fig)
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        self.test_preds.clear()
        self.test_labels.clear()
            
    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            filter(lambda p: p.requires_grad, self.model.parameters()),
            lr=self.hparams.lr
        )
        
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='max',
            factor=0.5,
            patience=3,
        )
        
        return {
            "optimizer": optimizer,
            "lr_scheduler": {
                "scheduler": scheduler,
                "monitor": "val/acc",
            }
        }
